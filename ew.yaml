experiment:
  name: "optml-main"
  seed: 0

paths:
  data: features_and_dh_returns.parquet

data:
  date_col: date
  group_col: date
  target: dh_ret
  moneyness_col: moneyness_std
  option_type_col: is_call
  features: []
  feature_groups:
    I:
      - moneyness_std
      - tau
      - is_call
      - delta_model
      - theta_model
      - gamma_model
      - vega_model
      - iv
      - log_mid_t
      - opt_rel_spread_final
      - opt_rel_spread_chg
      - baspread_chg
      - log_open_interest_opt
      - d_log_open_interest_opt

    B:
      - atm_iv
      - atm_term_slope
      - smile_slope
      - convexity_proxy
      - rr25_proxy
      - bf25_proxy
      - ivrv_ratio_pred
      - d_iv_atm
      - atm_ivchg_proxy
      - dist_to_wall
      - ddist_to_wall
      - gex_proxy
      - dgex_proxy
      - ddist_to_wall_date
      - dgex_proxy_date
      - oi_herf_date
      - log_pcr_oi_opt
      - d_log_pcr_oi_opt

    M:
      # - rv_pred                    # in master list, but commented in original
      - rv_chg
      - realskew_chg
      - fut_baspread_chg
      - fut_baspread_z
      - log_taker_buy_sell_ratio
      - log1p_taker_buy_volume
      - log1p_long_liquidations_usd
      - log1p_short_liquidations_usd
      - d_log_taker_buy_sell_ratio
      - d_log1p_taker_buy_volume
      - d_log1p_long_liquidations_usd
      - d_log1p_short_liquidations_usd
      - basis
      - d_basis
      - funding_rates
      - d_funding_rates
      - log_estimated_leverage_ratio
      - d_log_estimated_leverage_ratio
      - log_open_interest
      - d_log_open_interest
      - log_pcr_oi
      - d_log_pcr_oi
      - futmom_5
      - futmom_10
      - futmom_21
    C:
      - log1p_spot_inflow_total  
      - log1p_spot_outflow_total
      - asinh_spot_netflow_total
      - log1p_spot_reserve_usd
      - log1p_spot_transactions_count_inflow
      - log1p_spot_transactions_count_outflow
      - addresses_count_active
      - d_log1p_spot_inflow_total
      - d_log1p_spot_outflow_total
      - d_asinh_spot_netflow_total
      - d_log1p_spot_reserve_usd
      - d_log1p_spot_transactions_count_inflow
      - d_log1p_spot_transactions_count_outflow
      - log1p_der_inflow_total
      - d_log1p_der_inflow_total
      - log1p_der_outflow_total
      - d_log1p_der_outflow_total
      - log1p_der_transactions_count_inflow
      - d_log1p_der_transactions_count_inflow
      - log1p_der_transactions_count_outflow
      - d_log1p_der_transactions_count_outflow
      - asinh_der_netflow_total
      - d_asinh_der_netflow_total
    T:
      - z_gt
      - reddit_pos_z
      - reddit_neg_z
      - reddit_neu_z
    INTERACTIONS:
      - d_funding_rates_x_mny 
      - d_funding_rates_x_tau
      - d_log1p_spot_inflow_total_x_mny
      - d_log1p_spot_inflow_total_x_tau
      - d_log_open_interest_x_mny
      - d_log_open_interest_x_tau
      - d_log_pcr_oi_x_mny
      - d_log_pcr_oi_x_tau


  shift_features:
    enabled: false
    only_date_constant: true
    force_all: false

  exclusions_by_target:
    y_gamma: []
    y_vega: [price_per_vega]

  target_norm:
    kind: none
    abs: true
    floor: 1e-6
    # column: null
    # force: false

  target_guardrails:
    winsorize:
      enabled: true      # false to disable
      lower_q: 0.01
      upper_q: 0.99
      fit_on: train      # learn thresholds on train only
    transform:
      enabled: false     # true to enable
      kind: asinh        # asinh | log1p | none
      scale:
        method: mad

contracts:
  type: all
  moneyness: all
  atm_band: [-1.0, 1.0]

preprocess:
  linear_nn:
    min_non_null_frac: 0.60
    variance_threshold: 1e-12
    winsorize:
      lower_q: 0.005
      upper_q: 0.995
    impute: median
    yeo_johnson: true
    standardize: true
  trees:
    min_non_null_frac: 0.20
    variance_threshold: 1e-12
    winsorize:
      lower_q: 0.00
      upper_q: 1.00
    impute: median
    yeo_johnson: false
    standardize: false

split:
  scheme: time_ordered
  train_frac: 0.70
  val_frac: 0.15
  test_frac: 0.15
  purge_gap: 1
  expanding_eval:
    enabled: true
    freq: "M"
    min_train_months: 38

benchmark: zero

models:
  enable:
    linear:
      # - ols
      - ridge
      - lasso
      - elasticnet
      - pcr
      - pls
    nonlinear:
      - rf
      - lgbm_gbdt
      # - lgbm_gbdt_huber      # ← NEW Huber GBDT model
      - lgbm_dart
      # - lgbm_dart_huber      # ← NEW Huber DART model
      - ffn

tuning:
  strategy: random
  n_iter: 1
  keep_top_k: 1
  seed: 0
  build_family_ensemble: true
  cv:
    enabled: true
    kind: time_grouped
    n_splits: 4
    gap: 1
    use_train_plus_val: true
    min_train_size: 60
  spaces:
    ols: {}
    ridge:
      alpha:
        dist: loguniform
        low: 1e-6
        high: 10.0
      max_iter:
        values: [10000]
    lasso:
      alpha:
        dist: loguniform
        low: 1e-6
        high: 1.0
      max_iter:
        values: [10000]
    elasticnet:
      alpha:
        dist: loguniform
        low: 1e-6
        high: 1.0
      l1_ratio:
        dist: uniform
        low: 0.0
        high: 1.0
      max_iter:
        values: [10000]
    pcr:
      pca__n_components:
        values: [1, 2, 3, 4, 5, 6]
      ridge__alpha:
        values: [0.0001, 0.001, 0.01, 0.1, 1.0]
    pls:
      n_components:
        values: [1, 2, 3, 4, 5, 6]
    rf:
      n_estimators:
        values: [600, 1000, 1500]
      max_depth:
        values: [4, 6, 8, 12]
      max_features:
        values: ["sqrt", "log2"]
      min_samples_leaf:
        values: [5, 10, 20, 50]
      min_samples_split:
        values: [2, 5, 10]
      bootstrap:
        values: [true]
      max_samples:
        values: [0.5, 0.7, 0.9]
    lgbm_gbdt:
      n_estimators:
        values: [800, 1200, 2000, 3000]
      learning_rate:
        values: [0.003, 0.005, 0.01, 0.02]
      max_depth:
        values: [-1, 3, 4]
      num_leaves:
        values: [31, 63, 127]
      min_child_samples:
        values: [50, 100, 200, 400]
      subsample:
        values: [0.8, 1.0]
      colsample_bytree:
        values: [0.8, 1.0]
      reg_alpha:
        dist: loguniform
        low: 1e-6
        high: 10.0
      reg_lambda:
        dist: loguniform
        low: 1e-6
        high: 10.0
      max_bin:
        values: [63, 127, 255]
      bagging_freq:
        values: [1, 10]
      verbosity:
        values: [-1]
    lgbm_gbdt_huber:
      n_estimators:
        values: [600, 900, 1200]
      learning_rate:
        values: [0.005, 0.01, 0.05, 0.1]
      max_depth:
        values: [-1, 2, 3]
      num_leaves:
        values: [10, 15, 30, 45]
      min_child_samples:
        values: [150, 200, 300]
      min_split_gain:
        values: [0.0, 0.05, 0.1]
      min_child_weight:
        values: [0.001, 0.01, 0.1]
      subsample:
        values: [0.8, 1.0]
      colsample_bytree:
        values: [0.8, 1.0]
      reg_alpha:
        dist: loguniform
        low: 0.000001
        high: 1.0
      reg_lambda:
        dist: loguniform
        low: 0.000001
        high: 1.0
      max_bin:
        values: [63, 127, 255]
      bagging_freq:
        values: [1, 10]
      verbosity:
        values: [-1]
      huber_delta:
        values: [0.5, 1.0, 2.0]
    lgbm_dart:
      n_estimators:
        values: [800, 1200, 2000, 3000]
      learning_rate:
        values: [0.003, 0.005, 0.01, 0.02]
      max_depth:
        values: [-1, 3, 4]
      num_leaves:
        values: [31, 63, 127]
      min_child_samples:
        values: [50, 100, 200, 400]
      min_split_gain:
        values: [0.0, 0.05, 0.1]
      min_child_weight:
        values: [0.001, 0.01, 0.1]
      subsample:
        values: [0.8, 1.0]
      colsample_bytree:
        values: [0.8, 1.0]
      reg_alpha:
        dist: loguniform
        low: 1e-6
        high: 10.0
      reg_lambda:
        dist: loguniform
        low: 1e-6
        high: 10.0
      drop_rate:
        values: [0.05, 0.10, 0.15, 0.20]
      skip_drop:
        values: [0.10, 0.25, 0.50]
      max_drop:
        values: [10, 50]
      max_bin:
        values: [63, 127, 255]
      bagging_freq:
        values: [1, 10]
      verbosity:
        values: [-1]

    lgbm_dart_huber:
      n_estimators:
        values: [600, 900, 1200]
      learning_rate:
        values: [0.005, 0.01, 0.02, 0.03]
      max_depth:
        values: [-1, 3, 4]
      num_leaves:
        values: [15, 31, 63, 127]
      min_child_samples:
        values: [100, 150, 200, 300]
      min_split_gain:
        values: [0.0, 0.05, 0.1]
      min_child_weight:
        values: [0.001, 0.01, 0.1]
      subsample:
        values: [0.8, 1.0]
      colsample_bytree:
        values: [0.8, 1.0]
      reg_alpha:
        dist: loguniform
        low: 0.000001
        high: 1.0
      reg_lambda:
        dist: loguniform
        low: 0.000001
        high: 1.0
      drop_rate:
        values: [0.10, 0.15, 0.20]
      skip_drop:
        values: [0.10, 0.25]
      max_drop:
        values: [10, 50]
      max_bin:
        values: [63, 127, 255]
      bagging_freq:
        values: [1, 10]
      verbosity:
        values: [-1]
      huber_delta:
        values: [0.5, 1.0, 2.0]
    ffn:
      n_hidden_layers:
        values: [1, 2]
      hidden_width:
        values: [32, 64, 128]
      width_shrink:
        values: [1.0, 0.5]
      activation:
        values: ["relu", "tanh", "gelu"]
      dropout:
        dist: uniform
        low: 0.0
        high: 0.3
      learning_rate:
        values: [0.001, 0.0005, 0.0003, 0.0001]
      weight_decay:
        dist: loguniform
        low: 1e-6
        high: 1e-3
      max_epochs:
        values: [100, 200]
      batch_size:
        values: [128, 256, 512]
      patience:
        values: [10, 20]
      val_split:
        values: [0.1]
      seed:
        values: [0]
      device:
        values: ["auto"]
      loss:
        values: ["mse"]
      huber_delta:
        values: [0.5, 1.0, 2.0]



explain:
  shap:
    enabled: True
    models: ["best"]
    sample_rows: 500
    background_kmeans: 20
    check_additivity: false
    per_member: true

portfolio:
  n_bins: 3

logging:
  level: INFO
  show_progress: true
